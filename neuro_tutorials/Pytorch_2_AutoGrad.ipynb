{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Pytorch_logo.png/800px-Pytorch_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Pytorch Autograd </h2>\n",
    "<h4>Lets see Numpy do this!</h4>\n",
    "Now on to something that makes Pytorch (and other Deep Learning frameworks) unique, the auto-differentiable computational graphs! (don't worry about how this exactly works)<br>\n",
    "Remember how we compute the gradients of parameters (weights) of a model by \"backpropagation\". First we calculate the \"gradient\" of the loss with respect to the model's output and then using the chain rule find the gradient of the loss with respect to the parameters or the input and on and on for larger networks. Seems like a pretty repetitive process governed by some well known rules right? Well you know what is good at doing repetitive well defined things?!?! Computers!!<br>\n",
    "This \"automatic\" backpropagation (among other things) is what Pytorch REALLY gives us that makes training Neural Networks easy. So how does it do it? Well first Pytorch keeps track of everything we do!! (unless we tell it not to) It does this by forming a \"computational graph\" - a tree-like structure of all the operations we perform starting at some initial tensor. When we tell Pytorch to backpropagate from some point, it works backwards up this tree and calculates and stores the gradients with respect to the point from where we back propagated from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see an example of this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Gradients\n",
      "dy/dx 2.0\n",
      "dy/dw 4.0\n",
      "dy/db 1\n"
     ]
    }
   ],
   "source": [
    "# Define some values\n",
    "x1 = torch.FloatTensor([4])\n",
    "w1 = torch.FloatTensor([2])\n",
    "b1 = torch.FloatTensor([3])\n",
    "\n",
    "# Create a simple linear equation\n",
    "y = w1 * x1 + b1    # y = 2 * x + 3\n",
    "\n",
    "# We can easily work out the partial derivatives for this equation\n",
    "dy_dx = w1\n",
    "dy_dw = x1\n",
    "dy_db = 1\n",
    "\n",
    "print(\"Calculated Gradients\") \n",
    "print(\"dy/dx\", dy_dx.item())\n",
    "print(\"dy/dw\", dy_dw.item())\n",
    "print(\"dy/db\", dy_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Gradients\n",
      "dy/dx 2.0\n",
      "dy/dw 4.0\n",
      "dy/db 1.0\n"
     ]
    }
   ],
   "source": [
    "#lets create some tensors, requires_grad tells Pytorch we want to store the gradients for this tensor\n",
    "#we need to do this if we are working with basic Pytorch tensors\n",
    "x = torch.FloatTensor([4])\n",
    "x.requires_grad = True\n",
    "w = torch.FloatTensor([2])\n",
    "w.requires_grad = True\n",
    "b = torch.FloatTensor([3])\n",
    "b.requires_grad = True\n",
    "\n",
    "#By performing a simple computation Pytorch will build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "#Compute gradients via Pytorch's Autograd\n",
    "y.backward()\n",
    "\n",
    "#Print out the calculated gradients\n",
    "#These gradients are the gradients with respect to the point where we backprop'd from - y\n",
    "#Create your own equation and use the auto backprop to see the partial derivatives!\n",
    "print(\"Calculated Gradients\") \n",
    "print(\"dy/dx\", x.grad.item())    # x.grad = dy/dx = 2 \n",
    "print(\"dy/dw\", w.grad.item())    # w.grad = dy/dw = 4\n",
    "print(\"dy/db\", b.grad.item())   # b.grad = dy/db = 1  \n",
    "#Note: .item() simply returns a 0D Tensor as a Python scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Finding the optimum point </h3>\n",
    "We can use gradient decent to find the minimum of an equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find the minimum of a parabola!\n",
    "\n",
    "# Define the equation as a lambda function\n",
    "fx = lambda  x: 3 * x**2 + 2 * x + -1.2\n",
    "\n",
    "# Create a random point X\n",
    "x_ = torch.randn(1)\n",
    "x_.requires_grad = True\n",
    "\n",
    "# Lets use Pytorch's Autograd to find the gradient at this point\n",
    "y_ = fx(x_)\n",
    "y_.backward()\n",
    "\n",
    "# The gradient tells us the direction to travel to increase Y\n",
    "dy_dx_ = x_.grad.item()\n",
    "print(\"dy/dx is %.2f when x is %.2f\" % (dy_dx_, x_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take some steps to decend the gradient!\n",
    "\n",
    "# Create a random point X\n",
    "x_ = torch.randn(1)\n",
    "x_.requires_grad = True\n",
    "\n",
    "# Create some loggers\n",
    "x_logger = []\n",
    "y_logger = []\n",
    "\n",
    "# We'll keep track of how many steps we've done\n",
    "counter = 0\n",
    "\n",
    "# Set a scale for the step size\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialise the gradient to a large value\n",
    "dy_dx_ = 1000\n",
    "\n",
    "# We'll limit the max number of steps so we don't create an infinite loop\n",
    "max_num_steps = 1000\n",
    "\n",
    "# Keep taking steps untill the gradient is small\n",
    "while np.abs(dy_dx_) > 0.001:\n",
    "    # Get the Y point at the current x value\n",
    "    y_ = fx(x_)\n",
    "    \n",
    "    # Calculate the gradient at this point\n",
    "    y_.backward()\n",
    "    dy_dx_ = x_.grad.item()\n",
    "\n",
    "    # Pytorch will not keep track of operations within a torch.no_grad() block\n",
    "    # We don't want Pytorch to add our gradient decent step to the computational graph!\n",
    "    with torch.no_grad():\n",
    "        # Take a step down (decend) the curve\n",
    "        x_ -= learning_rate * dy_dx_\n",
    "        \n",
    "        # Pytorch will accumulate the gradient over multiple backward passes\n",
    "        # For our use case we don't want this to happen so we need to set it to zero\n",
    "        # After we have used it\n",
    "        x_.grad.zero_()\n",
    "        \n",
    "        # Log the X and Y points to plot\n",
    "        x_logger.append(x_.item())\n",
    "        y_logger.append(y_.item())\n",
    "        \n",
    "    counter += 1\n",
    "    \n",
    "    if counter == max_num_steps:\n",
    "        break\n",
    "\n",
    "print(\"Y minimum is %.2f and is when X = %.2f, found after %d steps\" % (y_.item(), x_.item(), counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the steps we have taken\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "ax.plot(x_logger, y_logger, marker=\"x\")\n",
    "\n",
    "for (x, y) in zip(x_logger, y_logger):\n",
    "    txt = \"(%.2f, %.2f)\" % (x, y)\n",
    "    ax.annotate(txt, (x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Curve fitting </h3>\n",
    "Instead of finding the minimum of a given equation lets try to fit a parabola to some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new equation\n",
    "fx2 = lambda  x: -0.55 * x**2 + 1.2 * x + -0.81\n",
    "\n",
    "# Create some noisy data\n",
    "x = torch.linspace(-5, 7, 200)\n",
    "random_data = fx2(x) + 2 * torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, random_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialise the parameters of a parabola\n",
    "a = torch.randn(1)\n",
    "b = torch.randn(1)\n",
    "c = torch.randn(1)\n",
    "\n",
    "y_out = a * x**2 + b * x + c\n",
    "\n",
    "# Plot against the data\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y_out)\n",
    "plt.scatter(x, random_data)\n",
    "print(\"y = %.2fx^2 + %.2fx + %.2f\" % (a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets perform gradient decent on the parameters of the parabola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the tensors for gradient decent\n",
    "params = torch.cat((a, b, c)).unsqueeze(1)\n",
    "# Create X matrix\n",
    "# [x^2 x 1]\n",
    "x_data = torch.cat(((x**2).unsqueeze(1), x.unsqueeze(1), torch.ones_like(x).unsqueeze(1)), 1)\n",
    "# Make sure the output Y is the right size\n",
    "y_data = random_data.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Matrix multiplication using the created tensors\n",
    "# we should get the same output as before\n",
    "y_pred = torch.mm(x_data, params)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y_pred)\n",
    "plt.scatter(x, random_data)\n",
    "print(\"y = %.2fx^2 + %.2fx + %.2f\" % (params[0], params[1], params[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lets perform our gradient decent loop!</h4>\n",
    "For curve fitting we DON'T want to minimize Y we want to minimize the MAGNITUDE of the difference between the predicted outputs and the REAL (ground truth) ouputs. One way to do that is to minimise the \"mean squared error\" between the real and \"predicted\" outputs. This objective is also known as our \"Loss Function\". <br><br>\n",
    "It may seem obvious, but we need to ensure that whatever our \"loss\" is, it is differentiable. That is, we need to ensure that it is possible to find the partial derivative between the loss and the parameters. <br>\n",
    "We also need to make sure it's possible for Pytorch to solve for the  partial derivatives/gradients. Any break in the computational graph will prevent Pytorch from backpropagating any further! <br>\n",
    "Examples of such breaks include turning a Pytorch tensor into a Numpy array (and back) and using the .detach() function on a Pytorch tensor! We also cannot backprob within a \"torch.no_grad\" block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the error to plot\n",
    "error_log = []\n",
    "counter = 0\n",
    "# Set the gradient scale\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# initialise the error to a large value\n",
    "error = 1000\n",
    "\n",
    "# We'll limit the max number of steps so we don't create an infinite loop\n",
    "max_num_steps = 1000\n",
    "\n",
    "# Re-create the parameter matrix here\n",
    "params = torch.cat((a, b, c)).unsqueeze(1)\n",
    "params.requires_grad = True\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# Loop until the error is below some threshold\n",
    "while error > 0.1:\n",
    "    # Perform a \"forward pass\" \n",
    "    # aka get the output Y for all X values\n",
    "    y_pred = torch.mm(x_data, params).squeeze()\n",
    "\n",
    "    # Define our error/loss\n",
    "    error = (y_pred - random_data).pow(2).mean()\n",
    "    \n",
    "    # NOTE: Pytorch will only backprop from a single value\n",
    "    # So we must perform some sort of \"reduction\" aka take the average/sum etc\n",
    "    error.backward()\n",
    "    error_log.append(error.item())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        params -= learning_rate * params.grad\n",
    "        params.grad.zero_()\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "    if counter == max_num_steps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(error_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How close is our equation?\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.mm(x_data, params)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(x, y_pred)\n",
    "    plt.scatter(x, random_data)\n",
    "    print(\"Predicted Equation:\")\n",
    "    print(\"y = %.2fx^2 + %.2fx + %.2f\" % (params[0], params[1], params[2]))\n",
    "    print(\"Real Equation:\")\n",
    "    print(\"y = %.2fx^2 + %.2fx + %.2f\" % (-0.55, 1.2, -0.81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
